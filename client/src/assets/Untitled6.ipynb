{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1-WMKUYSONEECsvA4V3gbT92RxRGj7_F0","authorship_tag":"ABX9TyPJkqz3E/iOWVclUrV97i3+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Rh4Av3NDcyPl"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# Define the basic residual block\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        # Shortcut connection\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += self.shortcut(residual)\n","        out = self.relu(out)\n","        return out\n","\n","# Define the ResNet model\n","class ResNet(nn.Module):\n","    def __init__(self, block, layers, num_classes=1000):\n","        super(ResNet, self).__init__()\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def _make_layer(self, block, out_channels, blocks, stride):\n","        layers = []\n","        layers.append(block(self.in_channels, out_channels, stride))\n","        self.in_channels = out_channels\n","        for _ in range(1, blocks):\n","            layers.append(block(out_channels, out_channels, stride=1))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","# Example usage\n","resnet_model = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes=1000)  # ResNet50 configuration\n","print(resnet_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pa9TRs5wc_xM","executionInfo":{"status":"ok","timestamp":1701955832975,"user_tz":-330,"elapsed":1182,"user":{"displayName":"01fe21bci011","userId":"06523761643792089710"}},"outputId":"27f0c132-cd9b-45cf-a802-0dd9349c7669"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): ResidualBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (1): ResidualBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (2): ResidualBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): ResidualBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (2): ResidualBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (3): ResidualBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): ResidualBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (2): ResidualBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (3): ResidualBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (4): ResidualBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (5): ResidualBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): ResidualBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResidualBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (2): ResidualBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","data_dir = '/content/drive/MyDrive/Classroom/ML Dataset'\n","filepaths = []\n","labels = []\n","\n","folds = os.listdir(data_dir)\n","for fold in folds:\n","    foldpath = os.path.join(data_dir, fold)\n","    filelist = os.listdir(foldpath)\n","    for file in filelist:\n","        fpath = os.path.join(foldpath, file)\n","        filepaths.append(fpath)\n","        labels.append(fold)\n","\n","# Concatenate data paths with labels into one dataframe\n","Fseries = pd.Series(filepaths, name= 'filepaths')\n","Lseries = pd.Series(labels, name='labels')\n","df = pd.concat([Fseries, Lseries], axis= 1)"],"metadata":{"id":"fj231h0igcxB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Assuming 'data' is your dataset\n","# 'labels' are corresponding labels or targets\n","# Set random_state to ensure reproducibility if needed\n","\n","labels=df.labels;\n","\n","train_data, val_data, train_labels, val_labels = train_test_split(\n","    df, labels, test_size=0.2, random_state=42\n",")\n","\n","# Now, train_data and train_labels contain 80% of the data for training,\n","# and val_data and val_labels contain 20% of the data for validation.\n"],"metadata":{"id":"up213t2Iqyn0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from sklearn.preprocessing import LabelEncoder\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, transform=None):\n","        self.dataframe = dataframe\n","        self.transform = transform\n","\n","        # Initialize label encoder\n","        self.label_encoder = LabelEncoder()\n","        self.dataframe['labels'] = self.label_encoder.fit_transform(self.dataframe['labels'])\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.dataframe.iloc[idx, 0]\n","        label = self.dataframe.iloc[idx, 1]\n","\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label\n","\n","# Define data transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","# Create DataLoader instances\n","train_dataset = CustomDataset(train_data, transform=transform)\n","val_dataset = CustomDataset(val_data, transform=transform)\n","\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"],"metadata":{"id":"_-cebfllsPE3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Instantiate ResNet model\n","resnet_model = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes=4).to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)  # You can adjust the learning rate\n","\n","# Training loop\n","num_epochs = 2  # Adjust as needed\n","for epoch in range(num_epochs):\n","    resnet_model.train()\n","\n","    for inputs, labels in train_loader:\n","       inputs = inputs.to(device)\n","       labels = labels.to(device)\n","       optimizer.zero_grad()\n","       outputs = resnet_model(inputs)\n","       loss = criterion(outputs, labels)\n","       loss.backward()\n","       optimizer.step()\n","\n","\n","    # Validation loop\n","    resnet_model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = resnet_model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {accuracy:.4f}\")\n","\n","# Save the trained model if needed\n","torch.save(resnet_model.state_dict(), \"resnet_model.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6HmoftTsXUq","executionInfo":{"status":"ok","timestamp":1701870532186,"user_tz":-330,"elapsed":417969,"user":{"displayName":"01fe21bci011","userId":"06523761643792089710"}},"outputId":"756fde0a-6535-40ad-a452-6419cadffb40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2, Validation Accuracy: 0.2879\n","Epoch 2/2, Validation Accuracy: 0.2576\n"]}]},{"cell_type":"code","source":["# Assuming you have a test dataset similar to the training and validation datasets\n","test_dataset = CustomDataset(val_data, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Set the model to evaluation mode\n","resnet_model.eval()\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        outputs = resnet_model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","test_accuracy = correct / total\n","print(f\"Test Accuracy: {test_accuracy:.4f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvuOfTgFsp4H","executionInfo":{"status":"ok","timestamp":1701870554523,"user_tz":-330,"elapsed":22342,"user":{"displayName":"01fe21bci011","userId":"06523761643792089710"}},"outputId":"38f7b339-214a-45e2-e7b1-8e89e94da6fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.2576\n"]}]},{"cell_type":"code","source":["# # Assuming you have a file path to a test image\n","# image_path = \"/content/20231129_091122.jpg\"\n","\n","# # Load the image\n","# image = Image.open(image_path).convert(\"RGB\")\n","\n","# # Apply transformations (same as used during training)\n","# transform = transforms.Compose([\n","#     transforms.Resize((224, 224)),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","# ])\n","\n","# input_image = transform(image)\n","# input_image = input_image.unsqueeze(0)  # Add batch dimension\n","\n","# # Set the model to evaluation mode\n","# resnet_model.eval()\n","\n","# # Perform inference\n","# with torch.no_grad():\n","#     input_image = input_image.to(device)\n","#     output = resnet_model(input_image)\n","\n","# # Get predicted class\n","# _, predicted_class = torch.max(output, 1)\n","# # Use the original labels from your dataset\n","# original_labels = val_data.iloc[0, 1]\n","\n","# print(f\"Predicted Class: {predicted_class.item()}, Original Class: {original_labels}\")\n","\n"],"metadata":{"id":"Wj_zctNLxEi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Instantiate ResNet model\n","resnet_model = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes=4).to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)  # You can adjust the learning rate\n","\n","# Training loop\n","num_epochs = 15  # Adjust as needed\n","for epoch in range(num_epochs):\n","    resnet_model.train()\n","\n","    for inputs, labels in train_loader:\n","       inputs = inputs.to(device)\n","       labels = labels.to(device)\n","       optimizer.zero_grad()\n","       outputs = resnet_model(inputs)\n","       loss = criterion(outputs, labels)\n","       loss.backward()\n","       optimizer.step()\n","\n","    # Validation loop\n","    resnet_model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = resnet_model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {accuracy:.4f}\")\n","\n","# Save the trained model if needed\n","torch.save(resnet_model.state_dict(), \"resnet_model2.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGeONeK0PLIV","executionInfo":{"status":"ok","timestamp":1701958941092,"user_tz":-330,"elapsed":1480608,"user":{"displayName":"01fe21bci011","userId":"06523761643792089710"}},"outputId":"3e4a8e54-5727-4406-fbdb-bd6330998bcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15, Validation Accuracy: 0.3030\n","Epoch 2/15, Validation Accuracy: 0.3485\n","Epoch 3/15, Validation Accuracy: 0.3636\n","Epoch 4/15, Validation Accuracy: 0.4545\n","Epoch 5/15, Validation Accuracy: 0.4242\n","Epoch 6/15, Validation Accuracy: 0.5909\n","Epoch 7/15, Validation Accuracy: 0.6667\n","Epoch 8/15, Validation Accuracy: 0.6818\n","Epoch 10/15, Validation Accuracy: 0.6212\n","Epoch 11/15, Validation Accuracy: 0.5000\n","Epoch 12/15, Validation Accuracy: 0.6818\n","Epoch 13/15, Validation Accuracy: 0.4848\n","Epoch 15/15, Validation Accuracy: 0.6667\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Instantiate ResNet model\n","resnet_model = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes=4).to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(resnet_model.parameters(), lr=0.0001)  # You can adjust the learning rate\n","\n","# Training loop\n","num_epochs = 20  # Adjust as needed\n","for epoch in range(num_epochs):\n","    resnet_model.train()\n","\n","    for inputs, labels in train_loader:\n","       inputs = inputs.to(device)\n","       labels = labels.to(device)\n","       optimizer.zero_grad()\n","       outputs = resnet_model(inputs)\n","       loss = criterion(outputs, labels)\n","       loss.backward()\n","       optimizer.step()\n","\n","\n","    # Validation loop\n","    resnet_model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = resnet_model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {accuracy:.4f}\")\n","\n","# Save the trained model if needed\n","torch.save(resnet_model.state_dict(), \"resnet_model3.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vh5ENq-AZHUq","outputId":"fcac6906-d9a0-4402-acf9-75f2ccb98ca7"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20, Validation Accuracy: 0.3030\n","Epoch 2/20, Validation Accuracy: 0.3030\n","Epoch 3/20, Validation Accuracy: 0.3030\n","Epoch 4/20, Validation Accuracy: 0.3333\n","Epoch 5/20, Validation Accuracy: 0.4394\n","Epoch 6/20, Validation Accuracy: 0.5909\n","Epoch 7/20, Validation Accuracy: 0.5606\n","Epoch 8/20, Validation Accuracy: 0.6515\n","Epoch 9/20, Validation Accuracy: 0.6818\n","Epoch 10/20, Validation Accuracy: 0.5758\n","Epoch 11/20, Validation Accuracy: 0.6515\n","Epoch 12/20, Validation Accuracy: 0.5303\n","Epoch 13/20, Validation Accuracy: 0.5000\n","Epoch 14/20, Validation Accuracy: 0.6364\n","Epoch 15/20, Validation Accuracy: 0.6364\n","Epoch 16/20, Validation Accuracy: 0.6515\n","Epoch 17/20, Validation Accuracy: 0.6364\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yTGzE9Jrfc3K"},"execution_count":null,"outputs":[]}]}